#!/usr/bin/env python3
"""
ğŸ¥ MEDEX ULTIMATE RAG - Sistema MÃ©dico Completo Definitivo
El sistema mÃ©dico de IA mÃ¡s completo jamÃ¡s creado

ğŸ¯ CARACTERÃSTICAS COMPLETAS:
âœ… Kimi K2-0711-Preview (modelo mÃ¡s avanzado)
âœ… RAG vectorial con base de conocimiento mÃ©dico completa
âœ… Streaming en tiempo real con razonamiento visible
âœ… DetecciÃ³n automÃ¡tica: Paciente vs Profesional
âœ… Emergencias: Protocolos automÃ¡ticos integrados
âœ… AnÃ¡lisis de imÃ¡genes mÃ©dicas con contexto RAG
âœ… BÃºsqueda web mÃ©dica + RAG local
âœ… Context caching para documentos mÃ©dicos
âœ… InterpretaciÃ³n de signos vitales y laboratorios
âœ… Protocolos clÃ­nicos completos
âœ… Base de datos de medicamentos
âœ… Valores normales de referencia
âœ… Historial conversacional inteligente
"""

import asyncio
import json
import re
import base64
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import sys
import os

# Agregar paths
sys.path.append(os.path.dirname(__file__))

from openai import OpenAI
from medical_knowledge_base import MedicalKnowledgeBase
from medical_rag_system import MedicalRAGSystem

class MedeXUltimateRAG:
    """Sistema mÃ©dico definitivo con RAG completo"""
    
    def __init__(self):
        self.api_key = "sk-moXrSMVmgKFHiIB1cDi1BCq7EPJ0D6JeUI0URgR2m5DwcNlK"
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.moonshot.ai/v1"
        )
        
        # Inicializar sistemas
        print("ğŸ§  Inicializando MedeX Ultimate RAG...")
        self.knowledge_base = MedicalKnowledgeBase()
        self.rag_system = MedicalRAGSystem()
        
        # Cargar Ã­ndice RAG si existe
        self.rag_system.load_index()
        
        self.conversation_history = []
        self.session_stats = {
            "queries": 0,
            "emergencies": 0,
            "professional_queries": 0,
            "patient_queries": 0,
            "images_analyzed": 0,
            "rag_searches": 0,
            "web_searches": 0
        }
        
        # Patrones de emergencia mejorados
        self.emergency_keywords = [
            'dolor precordial intenso', 'dolor toracico severo', 
            'no puedo respirar', 'dificultad respiratoria severa',
            'convulsiones', 'perdida conciencia', 'sangrado abundante',
            'dolor cabeza explosivo', 'peor dolor vida', 'shock',
            'paro cardiaco', 'paro respiratorio', 'coma'
        ]
        
        # Patrones profesionales mejorados
        self.professional_patterns = [
            r'paciente\s+de\s+\d+\s+aÃ±os',
            r'caso\s+clinico',
            r'diagnostico\s+diferencial',
            r'protocolo\s+de\s+manejo',
            r'dosis\s+de\s+\d+\s*mg',
            r'tratamiento\s+con\s+\w+',
            r'manejo\s+hospitalario',
            r'codigo\s+cie',
            r'seguimiento\s+ambulatorio'
        ]
        
        print("âœ… MedeX Ultimate RAG inicializado correctamente")
    
    def detect_user_type(self, query: str) -> str:
        """Detecta tipo de usuario con mayor precisiÃ³n"""
        query_lower = query.lower()
        
        # Verificar patrones profesionales
        professional_score = 0
        for pattern in self.professional_patterns:
            if re.search(pattern, query_lower):
                professional_score += 2
        
        # TÃ©rminos tÃ©cnicos mÃ©dicos
        technical_terms = [
            'icd', 'cie-10', 'protocolo', 'manejo', 'seguimiento',
            'dosis', 'mg', 'ml', 'via', 'endovenosa', 'intramuscular',
            'diagnostico diferencial', 'criterios', 'evidencia'
        ]
        
        for term in technical_terms:
            if term in query_lower:
                professional_score += 1
        
        # Indicadores de paciente
        patient_indicators = [
            'me duele', 'tengo', 'siento', 'estoy preocupado',
            'que sera', 'es normal', 'debo preocuparme',
            'mi hijo', 'mi esposo', 'mi mama'
        ]
        
        patient_score = 0
        for indicator in patient_indicators:
            if indicator in query_lower:
                patient_score += 2
        
        # DecisiÃ³n basada en puntuaciÃ³n
        if professional_score >= 3:
            return "professional"
        elif patient_score >= 2:
            return "patient"
        else:
            # AnÃ¡lisis por longitud y complejidad
            if len(query.split()) > 15 and any(word in query_lower for word in ['paciente', 'caso', 'aÃ±os']):
                return "professional"
            else:
                return "patient"
    
    def detect_emergency(self, query: str) -> bool:
        """Detecta emergencias mÃ©dicas con mayor precisiÃ³n"""
        query_lower = query.lower()
        
        # Palabras clave de emergencia directa
        for keyword in self.emergency_keywords:
            if keyword in query_lower:
                return True
        
        # Patrones de urgencia
        urgency_patterns = [
            r'dolor\s+(muy\s+)?intenso',
            r'no\s+puedo\s+\w+',
            r'desde\s+hace\s+\d+\s+horas?\s+y\s+(empeora|grave)',
            r'sangr(e|ando)\s+(mucho|abundante)',
            r'se\s+desmayo',
            r'esta\s+(inconsciente|grave)'
        ]
        
        for pattern in urgency_patterns:
            if re.search(pattern, query_lower):
                return True
        
        return False
    
    def get_rag_context(self, query: str, user_type: str, is_emergency: bool) -> str:
        """Obtiene contexto relevante del sistema RAG"""
        
        try:
            # BÃºsqueda contextual en RAG
            context_info = self.rag_system.get_contextual_information(
                query=query,
                user_type=user_type,
                urgency_level="emergency" if is_emergency else "routine"
            )
            
            self.session_stats['rag_searches'] += 1
            
            # Formatear contexto para prompt
            context_parts = []
            
            if context_info['general_results']:
                context_parts.append("=== INFORMACIÃ“N RELEVANTE DE BASE DE CONOCIMIENTO ===")
                
                for i, result in enumerate(context_info['general_results'][:3], 1):
                    context_parts.append(f"\n{i}. {result['title']} (CategorÃ­a: {result['category']})")
                    
                    if user_type == "professional" and result.get('full_content'):
                        # Contenido completo para profesionales
                        context_parts.append(f"   Detalles: {result['full_content'][:500]}...")
                    elif result.get('simplified_content'):
                        # Contenido simplificado para pacientes
                        context_parts.append(f"   InformaciÃ³n: {result['simplified_content']}")
                    
                    if result.get('emergency_relevant') and is_emergency:
                        context_parts.append("   âš ï¸ RELEVANTE PARA EMERGENCIA")
            
            # InformaciÃ³n especÃ­fica de emergencia
            if is_emergency and context_info['emergency_results']:
                context_parts.append("\n=== PROTOCOLOS DE EMERGENCIA ===")
                for result in context_info['emergency_results'][:2]:
                    context_parts.append(f"â€¢ {result.document.title}")
                    context_parts.append(f"  {result.document.content[:300]}...")
            
            return "\n".join(context_parts)
            
        except Exception as e:
            print(f"âš ï¸ Error obteniendo contexto RAG: {e}")
            return ""
    
    def create_enhanced_system_prompt(self, query: str, user_type: str, is_emergency: bool) -> str:
        """Crea prompt del sistema mejorado con contexto RAG"""
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Obtener contexto RAG
        rag_context = self.get_rag_context(query, user_type, is_emergency)
        
        base_prompt = f"""Eres MedeX Ultimate, el sistema de inteligencia artificial mÃ©dica mÃ¡s avanzado del mundo.

FECHA Y HORA: {current_time}
TIPO DE USUARIO: {user_type.upper()}
EMERGENCIA DETECTADA: {"SÃ" if is_emergency else "NO"}

ARQUITECTURA DEL SISTEMA:
- Motor Principal: Kimi K2-0711-Preview (modelo mÃ¡s avanzado)
- Base de Conocimiento: RAG vectorial con literatura mÃ©dica completa
- Capacidades: Streaming, multimodal, bÃºsqueda web, protocolos clÃ­nicos

{rag_context if rag_context else ""}

"""
        
        if user_type == "professional":
            base_prompt += """MODO PROFESIONAL MÃ‰DICO ACTIVADO:

PROTOCOLOS DE RESPUESTA PROFESIONAL:
- AnÃ¡lisis clÃ­nico detallado basado en evidencia cientÃ­fica
- DiagnÃ³sticos diferenciales con probabilidades estimadas segÃºn literatura
- Protocolos de manejo especÃ­ficos con dosis farmacolÃ³gicas exactas
- Citas de guÃ­as clÃ­nicas actuales cuando sea relevante
- Criterios de derivaciÃ³n y seguimiento segÃºn estÃ¡ndares
- TerminologÃ­a mÃ©dica apropiada y cÃ³digos CIE-10
- CorrelaciÃ³n con informaciÃ³n de base de conocimiento
- InterpretaciÃ³n de estudios paraclÃ­nicos

ESTRUCTURA DE RESPUESTA PROFESIONAL:
1. Resumen ejecutivo del caso
2. AnÃ¡lisis clÃ­nico detallado
3. DiagnÃ³sticos diferenciales priorizados
4. Plan de manejo especÃ­fico
5. Criterios de seguimiento
6. Referencias a protocolos institucionales

"""
        else:
            base_prompt += """MODO PACIENTE ACTIVADO:

PROTOCOLOS DE RESPUESTA PARA PACIENTES:
- Lenguaje claro, comprensible y empÃ¡tico
- InformaciÃ³n educativa sin crear ansiedad innecesaria
- ExplicaciÃ³n de cuÃ¡ndo es importante buscar atenciÃ³n mÃ©dica
- Medidas de autocuidado apropiadas y seguras
- Tono tranquilizador y de apoyo
- Evitar diagnÃ³sticos especÃ­ficos
- Enfoque en orientaciÃ³n y educaciÃ³n

ESTRUCTURA DE RESPUESTA PARA PACIENTES:
1. Acknowledgment empÃ¡tico de la preocupaciÃ³n
2. ExplicaciÃ³n clara de posibles causas
3. Recomendaciones de autocuidado
4. Signos de alarma para buscar atenciÃ³n
5. PrÃ³ximos pasos recomendados
6. TranquilizaciÃ³n apropiada

"""
        
        if is_emergency:
            base_prompt += """ğŸš¨ PROTOCOLO DE EMERGENCIA ACTIVADO ğŸš¨

INSTRUCCIONES CRÃTICAS DE EMERGENCIA:
- PRIORIDAD MÃXIMA: Seguridad inmediata del paciente
- Evaluar necesidad de atenciÃ³n mÃ©dica INMEDIATA
- Proporcionar pasos de acciÃ³n especÃ­ficos, claros y secuenciales
- Indicar CUÃNDO y CÃ“MO contactar servicios de emergencia
- NO minimizar sÃ­ntomas potencialmente graves
- Incluir instrucciones de primeros auxilios si aplicable
- Considerar protocolos de triage y estabilizaciÃ³n

ESTRUCTURA DE RESPUESTA DE EMERGENCIA:
1. ğŸš¨ EVALUACIÃ“N INMEDIATA DE RIESGO
2. ğŸ“ INSTRUCCIONES DE CONTACTO DE EMERGENCIA
3. ğŸ©¹ PRIMEROS AUXILIOS INMEDIATOS
4. â° MONITOREO HASTA LLEGADA DE AYUDA
5. ğŸ“‹ INFORMACIÃ“N PARA SERVICIOS MÃ‰DICOS

"""
        
        base_prompt += """CAPACIDADES ESPECIALES DISPONIBLES:
- ğŸ” BÃºsqueda en base de conocimiento mÃ©dico especializada
- ğŸŒ Acceso a informaciÃ³n mÃ©dica web actualizada
- ğŸ©» AnÃ¡lisis de imÃ¡genes mÃ©dicas (radiografÃ­as, ECGs, laboratorios)
- ğŸ“Š InterpretaciÃ³n de signos vitales y valores de laboratorio
- ğŸ’Š Base de datos completa de medicamentos con interacciones
- ğŸ“‹ Protocolos clÃ­nicos estandarizados
- ğŸ§¬ CorrelaciÃ³n con valores de referencia normales

INSTRUCCIONES DE INTEGRACIÃ“N RAG:
- Utiliza la informaciÃ³n de la base de conocimiento proporcionada
- Correlaciona con los hallazgos clÃ­nicos del paciente
- Prioriza informaciÃ³n especÃ­fica sobre informaciÃ³n general
- Menciona cuando la informaciÃ³n proviene de protocolos establecidos
- Integra seamlessly el conocimiento base con el razonamiento clÃ­nico

DISCLAIMERS MÃ‰DICOS OBLIGATORIOS:
- Esta informaciÃ³n es exclusivamente educativa
- NO reemplaza la consulta mÃ©dica profesional
- En emergencias reales, contactar servicios de emergencia (911)
- Siempre buscar evaluaciÃ³n mÃ©dica presencial para diagnÃ³stico definitivo
- Los protocolos pueden variar segÃºn instituciones y guÃ­as locales

INSTRUCCIONES DE RESPUESTA:
- Proporciona razonamiento clÃ­nico paso a paso
- Estructura la informaciÃ³n de manera lÃ³gica y clara
- Adapta el nivel de detalle tÃ©cnico al tipo de usuario
- Incluye referencias a la base de conocimiento cuando sea relevante
- MantÃ©n un balance entre completitud y claridad
- Siempre finaliza con disclaimers apropiados y prÃ³ximos pasos"""
        
        return base_prompt
    
    async def generate_ultimate_response(self, query: str, use_streaming: bool = True) -> str:
        """Genera respuesta mÃ©dica definitiva con RAG completo"""
        
        # Analizar query
        user_type = self.detect_user_type(query)
        is_emergency = self.detect_emergency(query)
        
        # Actualizar estadÃ­sticas
        self.session_stats['queries'] += 1
        if is_emergency:
            self.session_stats['emergencies'] += 1
        if user_type == "professional":
            self.session_stats['professional_queries'] += 1
        else:
            self.session_stats['patient_queries'] += 1
        
        # Crear prompt del sistema mejorado
        system_prompt = self.create_enhanced_system_prompt(query, user_type, is_emergency)
        
        # Configurar herramientas
        tools = None
        if not is_emergency:  # En emergencias, respuesta directa sin web search
            tools = [
                {
                    "type": "builtin_function",
                    "function": {"name": "$web_search"}
                }
            ]
        
        # Preparar mensajes con historial
        messages = [
            {"role": "system", "content": system_prompt},
        ]
        
        # Agregar historial conversacional reciente
        if self.conversation_history:
            for interaction in self.conversation_history[-2:]:  # Ãšltimas 2 interacciones
                if 'user_query' in interaction:
                    messages.append({"role": "user", "content": interaction['user_query']})
                if 'response' in interaction:
                    # Limitar longitud de respuestas anteriores
                    prev_response = interaction['response'][:800] + "..." if len(interaction['response']) > 800 else interaction['response']
                    messages.append({"role": "assistant", "content": prev_response})
        
        # Agregar query actual
        messages.append({"role": "user", "content": query})
        
        print(f"\nğŸ©º MedeX Ultimate RAG")
        print(f"   ğŸ‘¤ Usuario: {user_type.upper()}")
        print(f"   ğŸš¨ Emergencia: {'SÃ' if is_emergency else 'NO'}")
        print(f"   ğŸ” RAG: {len(self.rag_system.documents)} documentos indexados")
        
        try:
            if use_streaming:
                return await self._generate_streaming_with_rag(messages, tools, query, user_type, is_emergency)
            else:
                return await self._generate_direct_with_rag(messages, tools)
                
        except Exception as e:
            error_msg = f"Error en MedeX Ultimate RAG: {e}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    async def _generate_streaming_with_rag(self, messages: List[Dict], tools: Optional[List], 
                                         query: str, user_type: str, is_emergency: bool) -> str:
        """Genera respuesta con streaming y RAG"""
        
        print("ğŸ¤” Analizando con Kimi K2 + RAG...")
        
        finish_reason = None
        while finish_reason is None or finish_reason == "tool_calls":
            
            stream = self.client.chat.completions.create(
                model="kimi-k2-0711-preview",
                messages=messages,
                temperature=0.6 if not is_emergency else 0.3,  # Menor temperatura en emergencias
                max_tokens=3072,  # MÃ¡s tokens para respuestas completas
                stream=True,
                tools=tools
            )
            
            full_response = ""
            tool_calls = []
            current_message = {"role": "assistant", "content": ""}
            
            print(f"\nğŸ’¬ Respuesta MedeX Ultimate:")
            print("-" * 60)
            
            for chunk in stream:
                if chunk.choices:
                    choice = chunk.choices[0]
                    finish_reason = choice.finish_reason
                    
                    if choice.delta:
                        # Contenido normal con streaming visible
                        if choice.delta.content:
                            full_response += choice.delta.content
                            current_message["content"] += choice.delta.content
                            print(choice.delta.content, end="", flush=True)
                        
                        # Tool calls
                        if choice.delta.tool_calls:
                            for tool_call in choice.delta.tool_calls:
                                if len(tool_calls) <= tool_call.index:
                                    tool_calls.extend([None] * (tool_call.index + 1 - len(tool_calls)))
                                
                                if tool_calls[tool_call.index] is None:
                                    tool_calls[tool_call.index] = {
                                        "id": tool_call.id,
                                        "type": tool_call.type,
                                        "function": {"name": tool_call.function.name, "arguments": ""}
                                    }
                                
                                if tool_call.function.arguments:
                                    tool_calls[tool_call.index]["function"]["arguments"] += tool_call.function.arguments
            
            # Procesar tool calls si existen
            if finish_reason == "tool_calls" and tool_calls:
                current_message["tool_calls"] = [tc for tc in tool_calls if tc is not None]
                messages.append(current_message)
                
                print(f"\n\nğŸŒ Buscando informaciÃ³n mÃ©dica actualizada...")
                self.session_stats['web_searches'] += 1
                
                for tool_call in current_message["tool_calls"]:
                    if tool_call["function"]["name"] == "$web_search":
                        try:
                            arguments = json.loads(tool_call["function"]["arguments"])
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call["id"],
                                "name": "$web_search",
                                "content": json.dumps(arguments)
                            })
                        except:
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call["id"],
                                "name": "$web_search",
                                "content": json.dumps({"query": query})
                            })
            else:
                # Respuesta final
                print("\n" + "-" * 60)
                
                # Guardar en historial con informaciÃ³n enriquecida
                self.conversation_history.append({
                    "timestamp": datetime.now().isoformat(),
                    "user_query": query,
                    "response": full_response,
                    "user_type": user_type,
                    "is_emergency": is_emergency,
                    "rag_used": True,
                    "web_search_used": tools is not None
                })
                
                return full_response
        
        return full_response
    
    async def _generate_direct_with_rag(self, messages: List[Dict], tools: Optional[List]) -> str:
        """Genera respuesta directa con RAG"""
        
        response = self.client.chat.completions.create(
            model="kimi-k2-0711-preview",
            messages=messages,
            temperature=0.6,
            max_tokens=3072,
            tools=tools
        )
        
        return response.choices[0].message.content
    
    async def analyze_medical_image_with_rag(self, image_path: str, clinical_context: str = "") -> str:
        """Analiza imÃ¡genes mÃ©dicas con contexto RAG"""
        
        try:
            if not Path(image_path).exists():
                return f"âŒ Error: Archivo {image_path} no encontrado"
            
            # Obtener contexto RAG para el anÃ¡lisis de imagen
            rag_context = ""
            if clinical_context:
                context_info = self.rag_system.get_contextual_information(clinical_context)
                if context_info['general_results']:
                    rag_context = "\n=== CONTEXTO CLÃNICO RELEVANTE ==="
                    for result in context_info['general_results'][:2]:
                        rag_context += f"\nâ€¢ {result['title']}: {result.get('simplified_content', '')[:200]}..."
            
            # Leer y codificar imagen
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            file_ext = Path(image_path).suffix.lower()
            
            # Detectar tipo de usuario
            user_type = self.detect_user_type(clinical_context) if clinical_context else "patient"
            
            # Crear prompt especializado con contexto RAG
            if user_type == "professional":
                system_prompt = f"""Eres MedeX Ultimate, especialista en anÃ¡lisis de imÃ¡genes mÃ©dicas con acceso a base de conocimiento completa.

MODO PROFESIONAL - ANÃLISIS DE IMAGEN MÃ‰DICA:
- DescripciÃ³n tÃ©cnica detallada de hallazgos imagenolÃ³gicos
- InterpretaciÃ³n usando terminologÃ­a radiolÃ³gica apropiada
- DiagnÃ³sticos diferenciales imagenolÃ³gicos priorizados
- CorrelaciÃ³n clÃ­nica recomendada con base de conocimiento
- Estudios complementarios sugeridos segÃºn protocolos
- Limitaciones del anÃ¡lisis por IA claramente establecidas

{rag_context}

ESTRUCTURA DE REPORTE:
1. TÃ©cnica y calidad de la imagen
2. Hallazgos anatÃ³micos normales
3. Hallazgos patolÃ³gicos especÃ­ficos (si los hay)
4. DiagnÃ³sticos diferenciales imagenolÃ³gicos
5. CorrelaciÃ³n clÃ­nica recomendada
6. Estudios adicionales sugeridos
7. Limitaciones del anÃ¡lisis por IA"""
                
                user_prompt = f"""Analiza profesionalmente esta imagen mÃ©dica.

CONTEXTO CLÃNICO: {clinical_context}

Proporciona reporte radiolÃ³gico completo incluyendo:
- AnÃ¡lisis tÃ©cnico de la imagen
- DescripciÃ³n sistemÃ¡tica de hallazgos
- InterpretaciÃ³n clÃ­nica correlacionada
- Recomendaciones de manejo basadas en hallazgos
- Referencias a protocolos de la base de conocimiento cuando sea relevante

Incluye disclaimers sobre limitaciones de anÃ¡lisis por IA."""
            
            else:
                system_prompt = f"""Eres MedeX Ultimate, asistente que ayuda a pacientes a entender estudios mÃ©dicos.

MODO PACIENTE - EXPLICACIÃ“N DE IMAGEN MÃ‰DICA:
- Explicaciones claras y comprensibles sobre el estudio
- InformaciÃ³n educativa sin crear ansiedad innecesaria
- Ã‰nfasis en la importancia de consulta mÃ©dica profesional
- Lenguaje simple y empÃ¡tico
- OrientaciÃ³n sobre prÃ³ximos pasos

{rag_context}

ESTRUCTURA DE EXPLICACIÃ“N:
1. QuÃ© tipo de estudio es y para quÃ© sirve
2. QuÃ© se puede observar en tÃ©rminos generales
3. Importancia de discutir resultados con el mÃ©dico
4. QuÃ© preguntas hacer al mÃ©dico tratante
5. TranquilizaciÃ³n apropiada"""
                
                user_prompt = f"""Explica esta imagen mÃ©dica de manera comprensible para un paciente.

CONTEXTO: {clinical_context}

Proporciona explicaciÃ³n clara que incluya:
- QuÃ© tipo de estudio es
- QuÃ© informaciÃ³n puede proporcionar
- Por quÃ© es importante consultar con el mÃ©dico
- QuÃ© preguntas hacer al mÃ©dico
- TranquilizaciÃ³n apropiada

Usa lenguaje simple y evita crear ansiedad innecesaria."""
            
            # Configurar mensajes
            messages = [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image{file_ext};base64,{image_base64}"
                            }
                        },
                        {"type": "text", "text": user_prompt}
                    ]
                }
            ]
            
            print(f"ğŸ” Analizando imagen mÃ©dica con contexto RAG...")
            print(f"ğŸ“Š Modo: {user_type}")
            print(f"ğŸ§  Contexto RAG: {'Disponible' if rag_context else 'No disponible'}")
            
            # Generar anÃ¡lisis
            response = self.client.chat.completions.create(
                model="kimi-k2-0711-preview",
                messages=messages,
                temperature=0.3,  # Menor temperatura para precisiÃ³n mÃ©dica
                max_tokens=2048
            )
            
            result = response.choices[0].message.content
            
            # Actualizar estadÃ­sticas
            self.session_stats['images_analyzed'] += 1
            
            return result
            
        except Exception as e:
            return f"âŒ Error analizando imagen con RAG: {e}"
    
    def interpret_labs_and_vitals(self, data: Dict[str, Any]) -> str:
        """Interpreta laboratorios y signos vitales con contexto RAG"""
        
        try:
            interpretation_parts = []
            
            # Interpretar signos vitales si estÃ¡n presentes
            if 'vitals' in data:
                vitals_interpretation = self.knowledge_base.interpret_vital_signs(
                    data['vitals'],
                    data.get('age_group', 'adults')
                )
                
                interpretation_parts.append("=== SIGNOS VITALES ===")
                for vital, interpretation in vitals_interpretation.items():
                    value = data['vitals'][vital]
                    interpretation_parts.append(f"{vital}: {value} - {interpretation}")
            
            # Interpretar laboratorios si estÃ¡n presentes
            if 'labs' in data:
                labs_interpretation = self.knowledge_base.interpret_lab_values(
                    data['labs'],
                    data.get('gender', 'male')
                )
                
                interpretation_parts.append("\n=== LABORATORIOS ===")
                for lab, interpretation in labs_interpretation.items():
                    value = data['labs'][lab]
                    interpretation_parts.append(f"{lab}: {value} - {interpretation}")
            
            # Buscar condiciones relacionadas con valores anormales
            abnormal_findings = []
            if 'vitals' in data:
                for vital, interpretation in self.knowledge_base.interpret_vital_signs(data['vitals']).items():
                    if interpretation in ['Alto', 'Bajo']:
                        abnormal_findings.append(f"{vital} {interpretation.lower()}")
            
            if abnormal_findings:
                # Buscar en RAG condiciones relacionadas
                related_query = f"condiciones mÃ©dicas {' '.join(abnormal_findings)}"
                rag_results = self.rag_system.search_similar_documents(related_query, top_k=3)
                
                if rag_results:
                    interpretation_parts.append("\n=== POSIBLES CONDICIONES RELACIONADAS ===")
                    for result in rag_results:
                        interpretation_parts.append(f"â€¢ {result.document.title} (Similitud: {result.similarity_score:.2f})")
            
            return "\n".join(interpretation_parts)
            
        except Exception as e:
            return f"âŒ Error interpretando valores: {e}"
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """Obtiene estadÃ­sticas completas del sistema"""
        
        rag_stats = self.rag_system.get_statistics()
        
        return {
            **self.session_stats,
            "conversations": len(self.conversation_history),
            "model": "kimi-k2-0711-preview",
            "rag_system": rag_stats,
            "knowledge_base": {
                "conditions": len(self.knowledge_base.conditions),
                "medications": len(self.knowledge_base.medications),
                "procedures": len(self.knowledge_base.procedures),
                "protocols": len(self.knowledge_base.protocols)
            },
            "capabilities": [
                "Kimi K2 streaming",
                "RAG vectorial mÃ©dico",
                "Emergency detection",
                "Professional/Patient mode",
                "Medical image analysis",
                "Web search integration",
                "Vital signs interpretation",
                "Lab values interpretation",
                "Clinical protocols",
                "Conversational memory",
                "Context caching"
            ]
        }
    
    def save_session_data(self):
        """Guarda datos de la sesiÃ³n"""
        try:
            session_data = {
                "conversation_history": self.conversation_history,
                "session_stats": self.session_stats,
                "timestamp": datetime.now().isoformat()
            }
            
            with open("./rag_cache/session_data.json", 'w') as f:
                json.dump(session_data, f, ensure_ascii=False, indent=2)
            
            # Guardar Ã­ndice RAG actualizado
            self.rag_system.save_index()
            
            print("ğŸ’¾ Datos de sesiÃ³n guardados")
            
        except Exception as e:
            print(f"âš ï¸ Error guardando sesiÃ³n: {e}")

# Interfaz de chat ultimate
class MedeXUltimateChat:
    """Interfaz de chat para MedeX Ultimate RAG"""
    
    def __init__(self):
        self.medex = MedeXUltimateRAG()
        self.session_start = datetime.now()
    
    def print_ultimate_header(self):
        """Header del sistema ultimate"""
        print("\n" + "="*100)
        print("ğŸ¥ MEDEX ULTIMATE RAG - El Sistema MÃ©dico de IA MÃ¡s Completo del Mundo")
        print("ğŸ§  Kimi K2-0711-Preview + RAG Vectorial + Base de Conocimiento MÃ©dico Completa")
        print("âš¡ Sin limitaciones â€¢ 100% Real â€¢ Streaming + Razonamiento â€¢ Multimodal")
        print("="*100)
        print("ğŸ¯ CAPACIDADES ULTIMATE:")
        print("   ğŸ§  RAG Vectorial: Base de conocimiento mÃ©dico indexada semÃ¡nticamente")
        print("   ğŸ‘¤ DetecciÃ³n Inteligente: Paciente vs Profesional mÃ©dico automÃ¡tica")
        print("   ğŸš¨ Emergencias: Protocolos automÃ¡ticos integrados con RAG")
        print("   ğŸ©» AnÃ¡lisis Multimodal: ImÃ¡genes mÃ©dicas con contexto RAG")
        print("   ğŸŒ BÃºsqueda HÃ­brida: Web search + RAG local integrados")
        print("   ğŸ“Š InterpretaciÃ³n: Signos vitales y laboratorios con referencias")
        print("   ğŸ’Š Medicamentos: Base completa con interacciones y dosis")
        print("   ğŸ“‹ Protocolos: GuÃ­as clÃ­nicas estandarizadas")
        print("   ğŸ’¬ Streaming: Respuestas progresivas con razonamiento visible")
        print("   ğŸ§¬ Valores Normales: Referencias completas por edad y gÃ©nero")
        print("="*100)
        print("ğŸ’¡ COMANDOS ULTIMATE:")
        print("   ğŸ“¸ 'imagen [ruta] [contexto]' - AnÃ¡lisis de imagen con RAG")
        print("   ğŸ§ª 'laboratorio [valores]' - InterpretaciÃ³n con referencias")
        print("   ğŸ’Š 'medicamento [nombre] [contexto]' - Info completa con RAG")
        print("   ğŸ” 'buscar [termino]' - BÃºsqueda en base de conocimiento")
        print("   ğŸ“Š 'estadisticas' - Ver estadÃ­sticas completas del sistema")
        print("   ğŸ§¹ 'limpiar' - Limpiar historial")
        print("   ğŸ’¾ 'guardar' - Guardar sesiÃ³n")
        print("   ğŸšª 'salir' - Terminar")
        print("="*100)
        print("âš ï¸  Sistema mÃ©dico completo - Solo informaciÃ³n educativa")
        print("   ğŸ©º No reemplaza consulta mÃ©dica profesional")
        print("   ğŸš¨ En emergencias reales: Contactar servicios de emergencia")
        print("="*100 + "\n")
    
    async def handle_ultimate_commands(self, user_input: str) -> Optional[bool]:
        """Maneja comandos del sistema ultimate"""
        parts = user_input.lower().strip().split()
        command = parts[0] if parts else ""
        
        if command in ['salir', 'exit', 'quit']:
            print("\nğŸ‘‹ Cerrando MedeX Ultimate RAG...")
            
            # Guardar datos antes de salir
            self.medex.save_session_data()
            
            duration = datetime.now() - self.session_start
            print(f"â±ï¸  DuraciÃ³n de sesiÃ³n: {duration}")
            
            stats = self.medex.get_comprehensive_stats()
            print(f"ğŸ“Š Consultas procesadas: {stats['queries']}")
            print(f"ğŸ” BÃºsquedas RAG: {stats['rag_searches']}")
            print(f"ğŸŒ BÃºsquedas web: {stats['web_searches']}")
            print(f"ğŸ“¸ ImÃ¡genes analizadas: {stats['images_analyzed']}")
            print("ğŸ™ Â¡Gracias por usar MedeX Ultimate RAG!")
            return False
        
        elif command == 'estadisticas':
            stats = self.medex.get_comprehensive_stats()
            print(f"\nğŸ“Š ESTADÃSTICAS COMPLETAS DE MEDEX ULTIMATE:")
            print(f"   ğŸ’¬ Consultas totales: {stats['queries']}")
            print(f"   ğŸš¨ Emergencias detectadas: {stats['emergencies']}")
            print(f"   ğŸ‘¨â€âš•ï¸ Consultas profesionales: {stats['professional_queries']}")
            print(f"   ğŸ‘¤ Consultas de pacientes: {stats['patient_queries']}")
            print(f"   ğŸ“¸ ImÃ¡genes analizadas: {stats['images_analyzed']}")
            print(f"   ğŸ” BÃºsquedas RAG: {stats['rag_searches']}")
            print(f"   ğŸŒ BÃºsquedas web: {stats['web_searches']}")
            print(f"   ğŸ’¬ Conversaciones: {stats['conversations']}")
            print(f"\nğŸ§  SISTEMA RAG:")
            print(f"   ğŸ“š Documentos indexados: {stats['rag_system']['total_documents']}")
            print(f"   ğŸ—‚ï¸ CategorÃ­as: {stats['rag_system']['categories']}")
            print(f"   ğŸ’¾ Embeddings en cache: {stats['rag_system']['embeddings_cached']}")
            print(f"\nğŸ—„ï¸ BASE DE CONOCIMIENTO:")
            print(f"   ğŸ©º Condiciones mÃ©dicas: {stats['knowledge_base']['conditions']}")
            print(f"   ğŸ’Š Medicamentos: {stats['knowledge_base']['medications']}")
            print(f"   ğŸ”¬ Procedimientos: {stats['knowledge_base']['procedures']}")
            print(f"   ğŸ“‹ Protocolos: {stats['knowledge_base']['protocols']}")
            print(f"\nğŸ§  Modelo: {stats['model']}")
            return True
        
        elif command == 'limpiar':
            self.medex.conversation_history.clear()
            print("ğŸ§¹ Historial conversacional limpiado")
            return True
        
        elif command == 'guardar':
            self.medex.save_session_data()
            return True
        
        elif command == 'imagen':
            if len(parts) < 2:
                print("âŒ Uso: imagen [ruta_archivo] [contexto_clinico_opcional]")
                return True
            
            image_path = parts[1]
            context = " ".join(parts[2:]) if len(parts) > 2 else ""
            
            print(f"ğŸ“¸ Analizando imagen con RAG: {image_path}")
            result = await self.medex.analyze_medical_image_with_rag(image_path, context)
            print(f"\nğŸ©» ANÃLISIS DE IMAGEN CON RAG:")
            print("-" * 80)
            print(result)
            print("-" * 80)
            return True
        
        elif command == 'buscar':
            if len(parts) < 2:
                print("âŒ Uso: buscar [termino_medico]")
                return True
            
            search_term = " ".join(parts[1:])
            print(f"ğŸ” Buscando en base de conocimiento: {search_term}")
            
            results = self.medex.rag_system.search_similar_documents(search_term, top_k=5)
            
            print(f"\nğŸ“š RESULTADOS DE BÃšSQUEDA RAG:")
            print("-" * 60)
            for i, result in enumerate(results, 1):
                print(f"{i}. {result.document.title}")
                print(f"   CategorÃ­a: {result.document.category}")
                print(f"   Similitud: {result.similarity_score:.3f}")
                print(f"   Fuente: {result.document.source}")
                print()
            
            if not results:
                print("No se encontraron resultados relevantes.")
            print("-" * 60)
            return True
        
        return None
    
    async def chat_loop(self):
        """Loop principal del chat ultimate"""
        
        self.print_ultimate_header()
        print("ğŸš€ MedeX Ultimate RAG inicializado correctamente")
        print("ğŸ’¬ El sistema mÃ©dico mÃ¡s completo estÃ¡ listo para consultas...\n")
        
        try:
            while True:
                try:
                    user_input = input("ğŸ©º Consulta Ultimate: ").strip()
                    
                    if not user_input:
                        continue
                    
                    # Manejar comandos especiales
                    command_result = await self.handle_ultimate_commands(user_input)
                    
                    if command_result is False:
                        break
                    elif command_result is True:
                        continue
                    
                    # Procesar consulta mÃ©dica con sistema completo
                    await self.medex.generate_ultimate_response(user_input, use_streaming=True)
                    print("\n" + "â”€" * 80 + "\n")
                
                except KeyboardInterrupt:
                    print("\n\nâŒ¨ï¸  InterrupciÃ³n detectada...")
                    confirm = input("Â¿Salir de MedeX Ultimate? (s/N): ").lower()
                    if confirm in ['s', 'si', 'y', 'yes']:
                        break
                    else:
                        continue
                
                except Exception as e:
                    print(f"\nâŒ Error en sistema: {e}")
                    print("ğŸ’¡ El sistema continÃºa operativo. Intenta nueva consulta.")
        
        finally:
            print("\nğŸ¥ SesiÃ³n MedeX Ultimate RAG finalizada")
            self.medex.save_session_data()

# MÃ©todos adicionales para MedeXUltimateRAG
def add_missing_methods():
    """AÃ±ade mÃ©todos faltantes a la clase MedeXUltimateRAG"""
    
    async def process_query_async(self, query: str) -> str:
        """Procesa una consulta de forma asÃ­ncrona"""
        return self.process_query(query)
    
    def get_system_stats(self) -> Dict[str, Any]:
        """Obtiene estadÃ­sticas del sistema"""
        return {
            "knowledge_base_size": len(self.knowledge_base.get_all_conditions()),
            "embedding_model": "all-MiniLM-L6-v2",
            "rag_enabled": True,
            "queries_processed": len([msg for msg in self.conversation_history if msg["role"] == "user"]),
            "emergency_queries": len([msg for msg in self.conversation_history if msg.get("emergency_mode", False)]),
            "professional_queries": len([msg for msg in self.conversation_history if msg.get("user_type") == "professional"]),
            "rag_contexts_used": len([msg for msg in self.conversation_history if msg.get("rag_context_used", False)])
        }
    
    # AÃ±adir mÃ©todos a la clase
    MedeXUltimateRAG.process_query_async = process_query_async
    MedeXUltimateRAG.get_system_stats = get_system_stats

# AÃ±adir mÃ©todos adicionales para MedicalRAGSystem
def add_rag_methods():
    """AÃ±ade mÃ©todos faltantes a la clase MedicalRAGSystem"""
    
    def search_knowledge(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """Busca en la base de conocimiento usando RAG"""
        try:
            results = self.get_contextual_information(query)
            formatted_results = []
            
            # Combinar todos los tipos de resultados
            all_results = []
            if results.get('general_results'):
                all_results.extend(results['general_results'])
            if results.get('condition_results'):
                all_results.extend(results['condition_results'])
            if results.get('medication_results'):
                all_results.extend(results['medication_results'])
            
            # Formatear resultados
            for result in all_results[:top_k]:
                formatted_results.append({
                    'content': result.get('simplified_content', result.get('title', 'Sin contenido')),
                    'score': result.get('score', 0.0),
                    'type': result.get('type', 'general')
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"Error en bÃºsqueda: {e}")
            return []
    
    # AÃ±adir mÃ©todo a la clase
    MedicalRAGSystem.search_knowledge = search_knowledge

# Aplicar parches
add_missing_methods()
add_rag_methods()

# FunciÃ³n principal
async def main():
    """FunciÃ³n principal del sistema ultimate"""
    
    print("ğŸ¥ Iniciando MedeX Ultimate RAG...")
    print("ğŸ§  Cargando sistema mÃ©dico mÃ¡s completo del mundo...")
    
    try:
        chat = MedeXUltimateChat()
        await chat.chat_loop()
    except Exception as e:
        print(f"âŒ Error crÃ­tico del sistema: {e}")

if __name__ == "__main__":
    asyncio.run(main())